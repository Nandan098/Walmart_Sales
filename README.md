# Walmart_Sales
This project demonstrates a complete end-to-end data analytics workflow using real-world Walmart sales data. I extracted the dataset, performed thorough cleaning and transformation using Python, and loaded the refined data into MySQL to execute analytical queries and solve business case studies.

<h2>üìå Project Steps</h2>

<h3>1Ô∏è‚É£ <b>Environment Setup</b></h3>
<b>Tools Used:</b> Visual Studio Code, Python, MySQL & PostgreSQL  
‚Ä¢ Created a well-structured workspace with organized folders to ensure smooth development, data handling, and version control.

<h3>2Ô∏è‚É£ <b>Kaggle API Configuration</b></h3>
‚Ä¢ Generated and configured the Kaggle API token to enable direct dataset downloads.  
‚Ä¢ Placed the <b>kaggle.json</b> file in the local <b>.kaggle</b> directory.  
‚Ä¢ Downloaded dataset using:  
<code>kaggle datasets download -d &lt;dataset-path&gt;</code>

<h3>3Ô∏è‚É£ <b>Downloading Walmart Sales Data</b></h3>
‚Ä¢ Utilized the Kaggle API to download the Walmart Sales dataset.  
‚Ä¢ Stored the dataset in the <b>data/</b> folder for easy access and processing.

<h3>4Ô∏è‚É£ <b>Library Installation & Data Loading</b></h3>
‚Ä¢ Installed required Python packages:  
<code>pandas, numpy, sqlalchemy, mysql-connector-python, psycopg2</code>  
‚Ä¢ Loaded the dataset into a Pandas DataFrame for preprocessing and exploratory analysis.

<h3>5Ô∏è‚É£ <b>Exploratory Data Analysis (EDA)</b></h3>
Performed initial inspection using <code>.info()</code>, <code>.describe()</code>, and <code>.head()</code> to:  
‚Ä¢ Understand data distribution  
‚Ä¢ Identify datatype and schema issues  
‚Ä¢ Detect missing or inconsistent values

<h3>6Ô∏è‚É£ <b>Data Cleaning & Preparation</b></h3>
Executed comprehensive cleaning steps:  
‚Ä¢ Removed duplicate records  
‚Ä¢ Handled missing values  
‚Ä¢ Corrected data types (e.g., dates & currency formats)  
‚Ä¢ Formatted monetary values for consistency  
‚Ä¢ Validated dataset post-cleaning for further processing

<h3>7Ô∏è‚É£ <b>Feature Engineering</b></h3>
‚Ä¢ Created a new feature: <b>Total_Amount</b> calculated as:  
<code>unit_price √ó quantity</code>  
‚Ä¢ Enabled more effective SQL queries and revenue aggregation.

<h3>8Ô∏è‚É£ <b>Data Loading into MySQL & PostgreSQL</b></h3>
‚Ä¢ Established DB connections using <b>SQLAlchemy</b>  
‚Ä¢ Automated:  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Table creation  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Data insertion  
&nbsp;&nbsp;&nbsp;&nbsp;‚Ä¢ Schema alignment  
‚Ä¢ Verified loading with sample SQL queries.

---

<h2>üìä Project Flow Chart</h2>

```mermaid
flowchart TD
    A[Kaggle Dataset] --> B[Download via Kaggle API]
    B --> C[Python: Data Loading & Exploration]
    C --> D[Data Cleaning & Preparation]
    D --> E[Feature Engineering]
    E --> F[Load into MySQL]
    E --> G[Load into PostgreSQL]
    F --> H[SQL Queries & Business Insights]
    G --> H[SQL Queries & Business Insights]

